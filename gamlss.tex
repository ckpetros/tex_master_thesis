% !TEX root = Master.tex

\textit{\ac{GAMLSS}} \citep{rigby2001gamlss, rigby2005generalized} are a framework which surpass the limitations that come with \acp{GLM} and \acp{GAM}. Particularly, in \ac{GAMLSS} the assumption that the response variable $y$ belongs to a distribution of the exponential family is relaxed and a more general distribution family is permissible, including highly skewed and/or kurtotic distributions. In addition, other parameters besides the mean (or location) of the response's distribution can be modelled flexibly incorporating linear, non-linear and/or additive functions of covariates as well as random effects. By modelling the scale and shape parameters also, the issue of heteroscedasticity in the response is being handled. The models are fitted used maximum (penalised) likelihood estimation. Two algorithms can be used to fit the models, namely the CG and the RS algorithms, which can be looked upon in more detail in \cite{rigby2005generalized}.
\\

Independent observations $y_i$ for $i=1,2,\ldots,n$ with probability (density) function $f\left(y_{i} \mid \boldsymbol{\theta}^{i}\right)$, where $\boldsymbol{\theta}^{i}=\left(\theta_{i 1}, \theta_{i 2}, \ldots, \theta_{i p}\right)$ are assumed. Without loss of generality, $p$ is at most 4 and the parameters are denoted as $\left(\mu_{i}, \sigma_{i}, \nu_{i}, \tau_{i}\right)$, where the parameter $\mu_i$ is the location parameter, $\sigma_i$ is the scale parameter, and $\nu_i$ and $\tau_i$ are characterized as shape parameters. The model can be of course applied to distributions of any kind of parametric nature. Let $\mathbf{y}=\left(y_{1}, y_{2}, \ldots, y_{n}\right)^{\top}$ be the vector of the response variable and $g_k(.), k = 1,2,3,4$ be known monotonic link functions. Then 
\begin{equation}
\begin{array}{l}
g_{1}(\boldsymbol{\mu})=\eta_{1}=\mathbf{X}_{1} \boldsymbol{\beta}_{1}+\sum\limits_{j=1}^{J_{1}} h_{j 1}\left(\mathbf{x}_{j 1}\right) \\
g_{2}(\boldsymbol{\sigma})=\eta_{2}=\mathbf{X}_{2} \boldsymbol{\beta}_{2}+\sum\limits_{j=1}^{J_{2}} h_{j 2}\left(\mathbf{x}_{j 2}\right) \\
g_{3}(\boldsymbol{\nu})=\eta_{3}=\mathbf{X}_{3} \boldsymbol{\beta}_{3}+\sum\limits_{j=1}^{J_{3}} h_{j 3}\left(\mathbf{x}_{j 3}\right) \\
g_{4}(\boldsymbol{\tau})=\eta_{4}=\mathbf{X}_{4} \boldsymbol{\beta}_{4}+\sum\limits_{j=1}^{J_{4}} h_{j 4}\left(\mathbf{x}_{j 4}\right),
\end{array}
\label{eq:gamlss_equations}
\end{equation}
where $\bm{\mu}, \bm{\sigma}, \bm{\nu}, \bm{\tau}$ and $\bm{\eta}_k$ and $\bm{x}_{jk}$, for $j=1,\ldots,J_k$ and $k=1,2,3,4$ are vectors of length $n$. The explanatory variable $X_{jk}$ evaluated at $x_{jk}$ is described by the additive function $h_{jk}$. $X_k$ are fixed design matrices and $\beta_k$ are the parameter vectors.\footnote{According to \cite{stasinopoulos2007generalized}, in typical applications a constant is often adequate for each of the two shape parameters.}
\\

Note that the model \ref{eq:gamlss_equations}, also known as \textit{semi-parametric \ac{GAMLSS}} model, can be extended to allow random effect terms to be included for any parameter (more details can be found in the mentioned literature for this section).














